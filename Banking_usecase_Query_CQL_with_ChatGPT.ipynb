{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745",
      "metadata": {
        "id": "b69b5b27-f4dc-439b-8ae5-b3f776fa3745"
      },
      "source": [
        "# Using LLMs to Generate CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "107770b0-abda-43ee-af5d-eae2100b65ad",
      "metadata": {
        "id": "107770b0-abda-43ee-af5d-eae2100b65ad"
      },
      "source": [
        "Since LLMs seem to excel at a lot of things, we wanted to show how they can be used to generate CQL to query your Cassandra tables. This notebook provides a guide derived from the [SQL-PaLM](https://arxiv.org/abs/2306.00739) paper on how to automatically show the LLM your DB schema, and let it inform the LLM on querying your data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e",
      "metadata": {
        "id": "1ffeccb0-d70c-4f15-b924-6e8cd7a5b30e"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71640c3-3495-4459-837e-08d6e80ed410",
      "metadata": {
        "id": "b71640c3-3495-4459-837e-08d6e80ed410"
      },
      "source": [
        "#### Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
      "metadata": {
        "id": "b43e0d9c-c760-485f-877b-df577f2cfacf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ca9f1fd-ebac-4b89-a40a-a65f945cff45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.29.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/18.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, geomet, httpcore, cassandra-driver, httpx, openai\n",
            "Successfully installed cassandra-driver-3.29.0 geomet-0.2.1.post1 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "# Install requirements, if not already installed\n",
        "!pip install openai cassandra-driver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1",
      "metadata": {
        "id": "ae7063e7-80c4-49ae-84f1-3345aa3bbef1"
      },
      "source": [
        "#### Connect to Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
      "metadata": {
        "id": "9767fc7a-a9d8-4e89-b32c-805243700348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3890a711-ff93-4618-f1df-808e4b357618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Initialize the OpenAI Client\n",
        "import os\n",
        "\n",
        "from getpass import getpass\n",
        "import openai\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "client = openai.OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
      "metadata": {
        "id": "6a47bad8-9e13-41fa-af6d-724b72f702cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "92b3dee4-bae5-46fc-95db-2e60ddf38786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Astra DB Token: ··········\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2ca6b16f-cf67-4565-9a5d-e6cc611b502d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2ca6b16f-cf67-4565-9a5d-e6cc611b502d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving secure-connect-enablement-classic (1).zip to secure-connect-enablement-classic (1).zip\n",
            "Astra DB Keyspace: enablement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 256697d1-b172-4480-b148-5089346d2239-eu-west-1.db.astra.datastax.com:29042:ab854d5c-564b-4934-abe9-bdc826681350. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 256697d1-b172-4480-b148-5089346d2239-eu-west-1.db.astra.datastax.com:29042:ab854d5c-564b-4934-abe9-bdc826681350. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(135229243594336) 256697d1-b172-4480-b148-5089346d2239-eu-west-1.db.astra.datastax.com:29042:ab854d5c-564b-4934-abe9-bdc826681350> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 256697d1-b172-4480-b148-5089346d2239-eu-west-1.db.astra.datastax.com:29042:ab854d5c-564b-4934-abe9-bdc826681350. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "# Connect to a Cassandra Cluster and initialize the session\n",
        "import re\n",
        "\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from getpass import getpass\n",
        "from google.colab import files\n",
        "\n",
        "ASTRA_TOKEN = os.environ.get(\n",
        "    \"ASTRA_DB_TOKEN\",\n",
        "    getpass(\"Astra DB Token: \")\n",
        ")\n",
        "\n",
        "ASTRA_BUNDLE_PATH = os.environ.get(\n",
        "    \"ASTRA_DB_BUNDLE_PATH\",\n",
        "    list(files.upload().keys())[0],\n",
        ")\n",
        "\n",
        "ASTRA_KEYSPACE = os.environ.get(\n",
        "    \"ASTRA_DB_KEYSPACE\",\n",
        "    input(\"Astra DB Keyspace: \"),\n",
        ")\n",
        "\n",
        "cloud_config = {\n",
        "    'secure_connect_bundle': ASTRA_BUNDLE_PATH\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(\"token\", ASTRA_TOKEN)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect(keyspace=ASTRA_KEYSPACE)\n",
        "\n",
        "\n",
        "def execute_statement(statement: str):\n",
        "    # This is a simple wrapper around executing CQL statements in our\n",
        "    # Cassandra cluster, and either raising an error or returning the results\n",
        "    try:\n",
        "        rows = session.execute(statement)\n",
        "        return rows.all()\n",
        "    except:\n",
        "        print(f\"Query Failed: {statement}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890b2537-f585-4f31-bb20-ed71910eb586",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "890b2537-f585-4f31-bb20-ed71910eb586"
      },
      "source": [
        "#### (Optional) Dummy DB Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db89558d-f24b-4517-bf46-97c65c2071ac",
      "metadata": {
        "id": "db89558d-f24b-4517-bf46-97c65c2071ac"
      },
      "source": [
        "Feel free to skip this section if you are instead adapting the notebook to fit your existing Cassandra Database. Here, we will utilize the python `cassandra-driver` package to connect to a DB and create some fake tables. This schema is pulled from [this DataStax example](https://www.datastax.com/learn/data-modeling-by-example/digital-library-data-model) on creating a data model for a digital music library."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "session.execute(\"DROP TABLE IF EXISTS accounts\");\n",
        "session.execute(\"DROP TABLE IF EXISTS transactions\");\n",
        "session.execute(\"DROP TABLE IF EXISTS customers\");\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8oK6Ddpfkuf4"
      },
      "id": "8oK6Ddpfkuf4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_tables_cql = \"\"\"\n",
        "CREATE TABLE customers (\n",
        "    name TEXT PRIMARY KEY,\n",
        "    type TEXT,\n",
        "    balance DECIMAL,\n",
        "    created_at TIMESTAMP,\n",
        "    phone TEXT\n",
        ");\n",
        "\n",
        "CREATE TABLE accounts (\n",
        "    name TEXT PRIMARY KEY,\n",
        "    customer_name TEXT,\n",
        "    type TEXT,\n",
        "    balance DECIMAL,\n",
        "    created_at TIMESTAMP\n",
        ");\n",
        "\n",
        "CREATE TABLE transactions (\n",
        "    name TEXT,\n",
        "    account_id UUID,\n",
        "    type TEXT,\n",
        "    amount DECIMAL,\n",
        "    balance_after DECIMAL,\n",
        "    timestamp TIMESTAMP, -- Added missing comma here\n",
        "    PRIMARY KEY (name, account_id, amount)\n",
        ");\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Execute the CQL statements for table creation\n",
        "for statement in create_tables_cql.split(\";\"):\n",
        "    if len(statement.strip()):\n",
        "        session.execute(statement.strip())\n"
      ],
      "metadata": {
        "id": "shS5nt_Vkvzx"
      },
      "id": "shS5nt_Vkvzx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "from datetime import datetime\n",
        "\n",
        "# Assume these are executed after generating UUIDs for customers and accounts\n",
        "insert_fake_data_cql = \"\"\"\n",
        "INSERT INTO customers (name, type, balance, created_at, phone) VALUES ('John Doe', 'Personal', 1200.50, toTimestamp(now()), '555-1234');\n",
        "INSERT INTO customers (name, type, balance, created_at, phone) VALUES ('Jane Smith', 'Business', 5000.00, toTimestamp(now()), '555-5678');\n",
        "INSERT INTO customers (name, type, balance, created_at, phone) VALUES ('Alice Johnson', 'Personal', 750.25, toTimestamp(now()), '555-9012');\n",
        "INSERT INTO customers (name, type, balance, created_at, phone) VALUES ('Bob Brown', 'Business', 2250.00, toTimestamp(now()), '555-3456');\n",
        "INSERT INTO customers (name, type, balance, created_at, phone) VALUES ('Charlie Davis', 'Personal', 300.00, toTimestamp(now()), '555-7890');\n",
        "\n",
        "\n",
        "\n",
        "INSERT INTO accounts (name, customer_name, type, balance, created_at) VALUES ('Acc-JohnDoe', 'John Doe', 'Checking', 1200.50, toTimestamp(now()));\n",
        "INSERT INTO accounts (name, customer_name, type, balance, created_at) VALUES ('Acc-JaneSmith', 'Jane Smith', 'Savings', 5000.00, toTimestamp(now()));\n",
        "INSERT INTO accounts (name, customer_name, type, balance, created_at) VALUES ('Acc-AliceJohnson', 'Alice Johnson', 'Checking', 750.25, toTimestamp(now()));\n",
        "INSERT INTO accounts (name, customer_name, type, balance, created_at) VALUES ('Acc-BobBrown', 'Bob Brown', 'Savings', 2250.00, toTimestamp(now()));\n",
        "INSERT INTO accounts (name, customer_name, type, balance, created_at) VALUES ('Acc-CharlieDavis', 'Charlie Davis', 'Checking', 300.00, toTimestamp(now()));\n",
        "\n",
        "\n",
        "\n",
        "INSERT INTO transactions (name, account_id, type, amount, balance_after, timestamp) VALUES ('Transaction1', uuid(), 'Deposit', 100.00, 1300.50, toTimestamp(now()));\n",
        "INSERT INTO transactions (name, account_id, type, amount, balance_after, timestamp) VALUES ('Transaction2', uuid(), 'Withdrawal', 200.00, 4800.00, toTimestamp(now()));\n",
        "INSERT INTO transactions (name, account_id, type, amount, balance_after, timestamp) VALUES ('Transaction3', uuid(), 'Deposit', 50.00, 800.25, toTimestamp(now()));\n",
        "INSERT INTO transactions (name, account_id, type, amount, balance_after, timestamp) VALUES ('Transaction4', uuid(), 'Withdrawal', 100.00, 2150.00, toTimestamp(now()));\n",
        "INSERT INTO transactions (name, account_id, type, amount, balance_after, timestamp) VALUES ('Transaction5', uuid(), 'Deposit', 200.00, 500.00, toTimestamp(now()));\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "tCYGiESkkzLY"
      },
      "id": "tCYGiESkkzLY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2495b975-8342-4386-b92d-5ae05b783853",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "2495b975-8342-4386-b92d-5ae05b783853"
      },
      "source": [
        "## (Optional) Give the LLM Additional Context with the Built-in 'Comments' Column"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23820cb9-d683-48bb-9440-b398446df4c9",
      "metadata": {
        "id": "23820cb9-d683-48bb-9440-b398446df4c9"
      },
      "source": [
        "LLM response quality greatly depends on the context they've been given - the more concise descriptions they have access to, the better. We can choose to augment the DB schema we pass to the model by utilizing the built-in `comment` property of CQL tables.\n",
        "\n",
        "NOTE: You can also include these comments at table creation by using the `WITH <table property 1> AND <table property 2> ... AND comment = '<comment>'` syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a",
      "metadata": {
        "id": "04d67d6c-6938-46ac-a5b5-8baaea54272a"
      },
      "outputs": [],
      "source": [
        "add_comments_cql = f\"\"\"\n",
        "ALTER TABLE customers WITH comment = 'Customer profiles, uniquely identified by customer name.';\n",
        "\n",
        "ALTER TABLE accounts WITH comment = 'Bank accounts, uniquely identified by account name, associated with customer names.';\n",
        "\n",
        "ALTER TABLE transactions WITH comment = 'Banking transactions, uniquely identified by a composite key of transaction name, account_id, and amount.';\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db29bea2-7600-495b-b57b-e2937fb0753f",
      "metadata": {
        "id": "db29bea2-7600-495b-b57b-e2937fb0753f"
      },
      "outputs": [],
      "source": [
        "# This parses the text above into executable strings by the driver\n",
        "for line in add_comments_cql.split(\"\\n\"):\n",
        "    sc_loc = line.find(\";\")\n",
        "    if sc_loc > -1:\n",
        "        execute_statement(line[:sc_loc])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d",
      "metadata": {
        "id": "1a07cc49-7ba3-45ee-b2da-7fd297d8a86d"
      },
      "source": [
        "## Run Queries from User Questions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "942613bc-25aa-41cc-80e9-78ca15bcee06",
      "metadata": {
        "id": "942613bc-25aa-41cc-80e9-78ca15bcee06"
      },
      "source": [
        "#### Generating & Executing CQL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8542b137-2fd1-4105-a402-17358647f815",
      "metadata": {
        "id": "8542b137-2fd1-4105-a402-17358647f815"
      },
      "source": [
        "Now, we can ask ChatGPT to provide us with some queries that answer our questions! The prompt template we use is taken from [SQL-PaLM](https://arxiv.org/abs/2306.00739), and adapted to fit the CQL use case. In order to use it though, we need to retrieve the schema from our DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f442866-55e8-4284-83e1-705bb320250b",
      "metadata": {
        "id": "7f442866-55e8-4284-83e1-705bb320250b"
      },
      "outputs": [],
      "source": [
        "TEXT2CQL_PROMPT = \"\"\"Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
        "\n",
        "[Schema : values (type)]\n",
        "{schema}\n",
        "\n",
        "[Partition Keys]\n",
        "{partition_keys}\n",
        "\n",
        "[Clustering Keys]\n",
        "{clustering_keys}\n",
        "\n",
        "[Q]\n",
        "{question}\n",
        "\n",
        "[CQL]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_schema_partition_clustering_keys(keyspace: str = ASTRA_KEYSPACE) -> (str, str):\n",
        "    \"\"\"Generates a TEXT2CQL_PROMPT compatible schema for a keyspace\"\"\"\n",
        "    # Get all table names in our keyspace\n",
        "    table_names = execute_statement(\n",
        "        f\"SELECT table_name, comment FROM system_schema.tables WHERE keyspace_name = '{keyspace}'\"\n",
        "    )\n",
        "    tn_str = \", \".join([\"'\" + tn.table_name + \"'\" for tn in table_names])\n",
        "\n",
        "    # Now get all the column names corresponding to those tables\n",
        "    columns = execute_statement(\n",
        "        f\"SELECT * FROM system_schema.columns WHERE table_name IN ({tn_str}) AND keyspace_name = '{keyspace}' ALLOW FILTERING\"\n",
        "    )\n",
        "\n",
        "    # Now, we construct our prompt template formatted schema, partition_keys, and clustering keys\n",
        "    # from the table and column objects returned from the DB\n",
        "    schema = \" | \".join([\n",
        "        f\"{table.table_name} '{table.comment}' : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.type})\"\n",
        "            for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    partition_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            col.column_name for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"partition_key\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    clustering_keys = \" | \".join([\n",
        "        f\"{table.table_name} : \" + \" , \".join([\n",
        "            f\"{col.column_name} ({col.clustering_order})\" for col in columns\n",
        "            if col.table_name == table.table_name\n",
        "            and col.kind == \"clustering\"\n",
        "        ])\n",
        "        for table in table_names\n",
        "    ])\n",
        "    return schema, partition_keys, clustering_keys\n",
        "\n",
        "\n",
        "def execute_query_from_question(question: str, debug_cql: bool = True, debug_prompt: bool = False, return_cql: bool = False):\n",
        "    \"\"\"Generates and executes CQL from a user question based on LLM output\"\"\"\n",
        "    # Get all of the variables necessary to fill out the prompt\n",
        "    schema, partition_keys, clustering_keys = generate_schema_partition_clustering_keys()\n",
        "    prompt = TEXT2CQL_PROMPT.format(\n",
        "        schema=schema,\n",
        "        partition_keys=partition_keys,\n",
        "        clustering_keys=clustering_keys,\n",
        "        question=question,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Get generated CQL from the LLM (in this case gpt-3.5-turbo)\n",
        "    completion = client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    if debug_cql:\n",
        "        print(f\"Question: {question}\\nGenerated Query: {completion}\\n\")\n",
        "\n",
        "    # Need to trim trailing ';' if present to work with cassandra-driver\n",
        "    if completion.find(\";\") > -1:\n",
        "        completion = completion[:completion.find(\";\")]\n",
        "\n",
        "    results = execute_statement(completion)\n",
        "\n",
        "    if return_cql:\n",
        "        return (results, completion)\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
      "metadata": {
        "id": "dd55a635-d1f5-4463-afff-b98b7bf23b56",
        "outputId": "0adafd0b-f714-458b-9e77-e717454d5566",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "accounts 'Bank accounts, uniquely identified by account name, associated with customer names.' : balance (decimal) , created_at (timestamp) , customer_name (text) , name (text) , type (text) | customers 'Customer profiles, uniquely identified by customer name.' : balance (decimal) , created_at (timestamp) , name (text) , phone (text) , type (text) | transactions 'Banking transactions, uniquely identified by a composite key of transaction name, account_id, and amount.' : account_id (uuid) , amount (decimal) , balance_after (decimal) , name (text) , timestamp (timestamp) , type (text)\n",
            "\n",
            "[Partition Keys]\n",
            "accounts : name | customers : name | transactions : name\n",
            "\n",
            "[Clustering Keys]\n",
            "accounts :  | customers :  | transactions : account_id (asc) , amount (asc)\n",
            "\n",
            "[Q]\n",
            "What are the customer names with accounts with balance above 1000 , allow filtering ? \n",
            "\n",
            "[CQL]\n",
            "\n",
            "Question: What are the customer names with accounts with balance above 1000 , allow filtering ? \n",
            "Generated Query: SELECT customer_name FROM accounts WHERE balance > 1000 ALLOW FILTERING; \n",
            "\n",
            "This query will retrieve the customer names with accounts that have a balance above 1000. However, using \"ALLOW FILTERING\" in Cassandra is not recommended for large datasets as it can impact performance. In this case, the data model does not support answering such a question in a performant way without the use of secondary indexes or denormalization.\n",
            "\n",
            "[Row(customer_name='Bob Brown'), Row(customer_name='Jane Smith'), Row(customer_name='John Doe')]\n"
          ]
        }
      ],
      "source": [
        "# Show full prompting trace for a banking-related question\n",
        "print(execute_query_from_question(\"What are the customer names with accounts with balance above 1000 , allow filtering ? \", debug_prompt=True))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7adb085f-48af-422b-9e9e-15c2d02a4f58",
      "metadata": {
        "id": "7adb085f-48af-422b-9e9e-15c2d02a4f58"
      },
      "source": [
        "Pretty cool that it can find the data to answer our questions! Let's see if we can take this one step further, and actually generate coherent responses using this data:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8afb916-f30b-4bed-9e00-5e86b261d788",
      "metadata": {
        "id": "d8afb916-f30b-4bed-9e00-5e86b261d788"
      },
      "source": [
        "#### End to End Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09aa4a19-a284-4800-abb0-8d0e24185c38",
      "metadata": {
        "id": "09aa4a19-a284-4800-abb0-8d0e24185c38"
      },
      "source": [
        "Now, let's wrap up by showing how we can make a subsequent LLM call to answer the user's question with natural language. This completes a full \"RAG\" style pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483",
      "metadata": {
        "id": "dbb6002e-d5f1-408c-9bd3-e7ca4a329483"
      },
      "outputs": [],
      "source": [
        "ANSWER_PROMPT = \"\"\"Query:\n",
        "```\n",
        "{cql}\n",
        "```\n",
        "\n",
        "Output:\n",
        "```\n",
        "{results_repr}\n",
        "```\n",
        "===\n",
        "\n",
        "Given the above results from querying the DB, answer the following user question:\n",
        "\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def answer_question(question: str, debug_cql: bool = False, debug_prompt: bool = False) -> str:\n",
        "    \"\"\"Conducts a full RAG pipeline where the LLM retrieves relevant information\n",
        "    and references it to answer the question in natural language.\n",
        "    \"\"\"\n",
        "    # Get necessary fields to fill out prompt\n",
        "    query_results, cql = execute_query_from_question(\n",
        "        question=question,\n",
        "        debug_cql=debug_cql,\n",
        "        debug_prompt=debug_prompt,\n",
        "        return_cql=True,\n",
        "    )\n",
        "    prompt = ANSWER_PROMPT.format(\n",
        "        question=question,\n",
        "        results_repr=str(query_results),\n",
        "        cql=cql,\n",
        "    )\n",
        "\n",
        "    if debug_prompt:\n",
        "        print(f\"Prompting model with:\\n{prompt}\")\n",
        "\n",
        "    # Return the generated answer from the LLM\n",
        "    return client.chat.completions.create(\n",
        "        messages=[{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }],\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "    ).choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show full prompting trace\n",
        "print(\n",
        "    answer_question(\"What is the amount of Transaction1?\", debug_prompt=True)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yCybjYxiCNi",
        "outputId": "230644ab-f971-4314-9ed7-3e15eb7008b6"
      },
      "id": "0yCybjYxiCNi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "accounts 'Bank accounts, uniquely identified by account name, associated with customer names.' : balance (decimal) , created_at (timestamp) , customer_name (text) , name (text) , type (text) | customers 'Customer profiles, uniquely identified by customer name.' : balance (decimal) , created_at (timestamp) , name (text) , phone (text) , type (text) | transactions 'Banking transactions, uniquely identified by a composite key of transaction name, account_id, and amount.' : account_id (uuid) , amount (decimal) , balance_after (decimal) , name (text) , timestamp (timestamp) , type (text)\n",
            "\n",
            "[Partition Keys]\n",
            "accounts : name | customers : name | transactions : name\n",
            "\n",
            "[Clustering Keys]\n",
            "accounts :  | customers :  | transactions : account_id (asc) , amount (asc)\n",
            "\n",
            "[Q]\n",
            "What is the amount of Transaction1?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Prompting model with:\n",
            "Query:\n",
            "```\n",
            "SELECT amount FROM transactions WHERE name = 'Transaction1'\n",
            "```\n",
            "\n",
            "Output:\n",
            "```\n",
            "[Row(amount=Decimal('100.00')), Row(amount=Decimal('100.00'))]\n",
            "```\n",
            "===\n",
            "\n",
            "Given the above results from querying the DB, answer the following user question:\n",
            "\n",
            "What is the amount of Transaction1?\n",
            "\n",
            "The amount of Transaction1 is $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoN_7MyvxTf6"
      },
      "id": "DoN_7MyvxTf6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show full prompting trace\n",
        "print(\n",
        "    answer_question(\"What is the type of Transaction5 and the balance_after ?\", debug_prompt=True)\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE9068UxkRpe",
        "outputId": "e2626b1e-e67b-4601-ad31-0ef36366c7d3"
      },
      "id": "gE9068UxkRpe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "accounts 'Bank accounts, uniquely identified by account name, associated with customer names.' : balance (decimal) , created_at (timestamp) , customer_name (text) , name (text) , type (text) | customers 'Customer profiles, uniquely identified by customer name.' : balance (decimal) , created_at (timestamp) , name (text) , phone (text) , type (text) | transactions 'Banking transactions, uniquely identified by a composite key of transaction name, account_id, and amount.' : account_id (uuid) , amount (decimal) , balance_after (decimal) , name (text) , timestamp (timestamp) , type (text)\n",
            "\n",
            "[Partition Keys]\n",
            "accounts : name | customers : name | transactions : name\n",
            "\n",
            "[Clustering Keys]\n",
            "accounts :  | customers :  | transactions : account_id (asc) , amount (asc)\n",
            "\n",
            "[Q]\n",
            "What is the type of Transaction5 and the balance_after ?\n",
            "\n",
            "[CQL]\n",
            "\n",
            "Prompting model with:\n",
            "Query:\n",
            "```\n",
            "SELECT type, balance_after FROM transactions WHERE name = 'Transaction5'\n",
            "```\n",
            "\n",
            "Output:\n",
            "```\n",
            "[Row(type='Deposit', balance_after=Decimal('500.00'))]\n",
            "```\n",
            "===\n",
            "\n",
            "Given the above results from querying the DB, answer the following user question:\n",
            "\n",
            "What is the type of Transaction5 and the balance_after ?\n",
            "\n",
            "The type of Transaction5 is 'Deposit' and the balance_after is $500.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QUz1_nayQQq"
      },
      "id": "4QUz1_nayQQq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
      "metadata": {
        "id": "8533ecb1-9c8e-4db1-beb4-e736d2a1b500",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81a27b5c-fcf4-457e-c223-4e6dd6b958b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompting model with:\n",
            "Convert the question to CQL (Cassandra Query Language) that can retrieve an appropriate answer, or answer saying that the data model does not support answering such a question in a performant way:\n",
            "\n",
            "[Schema : values (type)]\n",
            "accounts 'Bank accounts, uniquely identified by account name, associated with customer names.' : balance (decimal) , created_at (timestamp) , customer_name (text) , name (text) , type (text) | customers 'Customer profiles, uniquely identified by customer name.' : balance (decimal) , created_at (timestamp) , name (text) , phone (text) , type (text) | transactions 'Banking transactions, uniquely identified by a composite key of transaction name, account_id, and amount.' : account_id (uuid) , amount (decimal) , balance_after (decimal) , name (text) , timestamp (timestamp) , type (text)\n",
            "\n",
            "[Partition Keys]\n",
            "accounts : name | customers : name | transactions : name\n",
            "\n",
            "[Clustering Keys]\n",
            "accounts :  | customers :  | transactions : account_id (asc) , amount (asc)\n",
            "\n",
            "[Q]\n",
            "What is the account type of John Doe and its balance allow filtering? \n",
            "\n",
            "[CQL]\n",
            "\n",
            "Prompting model with:\n",
            "Query:\n",
            "```\n",
            "SELECT type, balance FROM accounts WHERE customer_name = 'John Doe' ALLOW FILTERING\n",
            "```\n",
            "\n",
            "Output:\n",
            "```\n",
            "[Row(type='Checking', balance=Decimal('1200.50'))]\n",
            "```\n",
            "===\n",
            "\n",
            "Given the above results from querying the DB, answer the following user question:\n",
            "\n",
            "What is the account type of John Doe and its balance allow filtering? \n",
            "\n",
            "The account type of John Doe is Checking and its balance is 1200.50.\n"
          ]
        }
      ],
      "source": [
        "# Show full prompting trace\n",
        "print(\n",
        "    answer_question(\"What is the account type of John Doe and its balance allow filtering? \", debug_prompt=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8",
      "metadata": {
        "id": "29edd522-6cb9-454c-a5b3-b8ee0f8a9ea8"
      },
      "source": [
        "Awesome! Our model is answering questions based on just the data in our dummy DB, and is able to construct queries for retrieving that data in a fully automated way."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}